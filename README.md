# Awesome Optimizers

This repository is concieved to provide aid in literature reiviews to Optimization researchers by offering an up-to-date list of literature and corresponding summaries.

If this repository has been useful to you in your research, please cite it using the *_cite this repository_* option available in Github. Thanks! :sparkling_heart:

### Table of Contents

- [Legend](#legend)
- [First-order Optimizers](#first-order-optimizers)
    - [Adaptive Optimizers](#adaptive-optimizers)
- [Second-order Optimizers](#second-order-optimizers)
-

### Legend

| Symbol        | Meaning |
|---------------|---------|
| :outbox_tray: | Summary |
| :computer:    | Code    |


## First-order Optimizers

- []


### Adaptive Optimizers

## Second-order Optimizers

## Optimizer-agnostic improvements

- [Gradient Centralization: A New Optimization Technique for Deep Neural Networks](https://arxiv.org/abs/2004.01461) [:outbox_tray:]() [:computer:]()

    Hongwei Yong, Jianqiang Huang, Xiansheng Hua, Lei Zhang; 2020


- [Gradient Descent: The Ultimate Optimizer](https://arxiv.org/abs/1909.13371) [:outbox_tray:]() [:computer:]()

    Kartik Chandra, Audrey Xie, Jonathan Ragan-Kelley, Erik Meijer; 2019